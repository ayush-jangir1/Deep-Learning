🧠 Deep Learning Playground
Where neurons fire, weights adjust, and overfitting is just a phase.
Welcome to my deep learning sandbox — or should I say lab of controlled chaos? 🤖✨
Here, models don't just learn, they evolve, sometimes cry in gradients, and occasionally throw a tantrum in the form of vanishing losses. This repo is my open diary of exploring the mysterious inner workings of neural networks — from basic building blocks to architectures that probably dream in tensors.

🧩 What’s Inside?
A delightful mix of:
Beginner-friendly notebooks (because no one is born knowing backprop)

Intermediate-level experiments (where I poke models till they behave)

Advanced architectures (a.k.a. the ones that require coffee and GPU sacrifices)

Failures (yes, they’re here too — because in DL, even your loss has value)

Remember: behind every great neural net is a human who Googled “why my model accuracy stuck at 50%” at least once.
Thanks for stopping by, and may your weights always converge! 

P.S. – Okay, you caught me — I had a little help from ChatGPT writing this😅. But hey, it takes a neural network to truly understand the struggles, dreams, and existential dread of another neural network. Think of it as AI helping me decode AI — poetic, right? 😄😄😄😄
